
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/">

	<link rel="stylesheet" href="./index_files/jemdoc.css" type="text/css">
	<title>Wei Jiang @ LAMDA, NJU-CS</title>
	<style>
		h2 {
			color: #880000;
			font-weight: 600;
		}
	</style>
</head>

<body>
	<div id="layout-content">
		<div id="toptitle">
			<h1>Wei Jiang @ LAMDA, NJU-CS</h1>
		</div>
		<table class="imgtable">
			<tbody>
				<tr>
					<td>
						<a href="./index_files/jiangwei.jpg"><img src="./index_files/jiangwei.jpg" alt="jiangwei.jpg"
								width="150px" height="200px"></a>&nbsp;</td>
					<td align="left">
						<p><b>
								<font size="+4" face="STKaiti">姜伟</font>
							</b><br>
							<font size="+2">Wei Jiang</font>
							<br>
							Ph.D. student, <a href="http://www.lamda.nju.edu.cn/CH.MainPage.ashx">LAMDA Group</a><br>
							<a href="https://cs.nju.edu.cn/">Department of Computer Science and Technology</a> <br>
							<a href="https://keysoftlab.nju.edu.cn/">National Key Laboratory for Novel Software
								Technology</a> <br>
							<a href="https://www.nju.edu.cn/">Nanjing University</a>, Nanjing 210023, China<br><br>

					</td>
					<td valign="top" width="179">
						<p align="center"><a href="http://www.lamda.nju.edu.cn/" target="_blank"><img height="85"
									src="./index_files/lamda.jpg" width="179" border="0" align="top"></a></p>
						<p align="center"><a href="http://www.nju.edu.cn/" target="_blank"><img height="120"
									src="./index_files/nju.jpg" width="100" border="0"></a></p>
					</td>
				</tr>
			</tbody>
		</table>
		</td>
		</tr>
		</tbody>
		</table><br>


		<h2>Supervisor</h2>
		<p> &nbsp; &nbsp;&nbsp;&nbsp; Professor <a href="http://ai.nju.edu.cn/zlj/" target="_blank"> Lijun Zhang </a> <br></p>

		<h2>Biography</h2>
		<ul>
			<li>
				<p><b>Sep 2016 - Jun 2020</b> : Receive my B.Sc. degree in Department of Computer Science and Technology (Honors Science Program) in <a href="http://www.xjtu.edu.cn/">Xi'an Jiaotong University</a>.
				</p>
			</li>
			<li>
				<p><b>Sep 2020 - Now</b> : Admitted to study for a Ph.D. degree in <a href="http://www.nju.edu.cn/"
						target="_blank">Nanjing University</a> without entrance examination.</p>
			</li>
		</ul>

		<h2>Research Interests</h2>
		<p>&nbsp; &nbsp;&nbsp;&nbsp; My research interests include <b>Machine Learning</b>, <b>Stochastic Optimization</b> and <b>Online learning</b>.</p> 

		<H2><a name="Preprints">Preprints</a></H2>
		<ol>
			<li> Adaptive Variance Reduction for Stochastic Optimization under Weaker Assumptions [<a href="https://arxiv.org/pdf/2406.01959" target="_blank">arXiv</a>]<br>   
			<b>W. Jiang</b>, S. Yang, Y. Wang, L. Zhang<br><br>
			<li> Efficient Sign-Based Optimization: Accelerating Convergence via Variance Reduction [<a href="https://arxiv.org/pdf/2406.00489" target="_blank">arXiv</a>]<br>   
			<b>W. Jiang</b>, S. Yang, W. Yang, L. Zhang<br><br>
		</ol>

		<h2>Publication</h2>
		<ol>

				<li> Projection-Free Variance Reduction Methods for Stochastic Constrained Multi-Level Compositional Optimization<br>   
				<b>W. Jiang</b>, S. Yang, W. Yang, Y. Wang, Y. Wan, and L. Zhang<br>	
				In Proceedings of the 41th International Conference on Machine Learning (<b>ICML 2024</b>), to appear, 2024.<br><br>

				<li> Small-loss Adaptive Regret for Online Convex Optimization<br>   
				W. Yang, <b>W. Jiang</b>, Y. Wang, P. Yang, Y. Hu, and L. Zhang<br>	
				In Proceedings of the 41th International Conference on Machine Learning (<b>ICML 2024</b>), to appear, 2024.<br><br>

				<li> Efficient Algorithms for Empirical Group Distributional Robust Optimization and Beyond<br>   
				D. Yu, Y. Cai, <b>W. Jiang</b>, and L. Zhang<br>	
				In Proceedings of the 41th International Conference on Machine Learning (<b>ICML 2024</b>), to appear, 2024.<br><br>

				</li><li> Non-stationary Projection-free Online Learning with Dynamic and Adaptive Regret Guarantees [<a href="https://arxiv.org/abs/2305.11726" target="_blank">arXiv</a>]<br>   
				Y. Wang, W. Yang, <b>W. Jiang</b>, S. Lu, B. Wang, H. Tang, Y. Wan, and L. Zhang<br>	
				In Proceedings of the 38th AAAI Conference on Artificial Intelligence (<b>AAAI 2024</b>),  to appear, 2024. <br><br>

				<li> Learning Unnormalized Statistical Models via Compositional Optimization  [<a href="./pdf/ICML-2023-Jiang.pdf" target="_blank">PDF</a>]<br>   
				<b>W. Jiang</b>, J. Qin, L. Wu, C. Chen, T. Yang, L. Zhang<br>	
				In Proceedings of the 40th International Conference on Machine Learning (<b>ICML 2023</b>), pages 15105 - 15124, 2023.<br><br>
				<li> Multi-block-Single-probe Variance Reduced Estimator for Coupled Compositional Optimization [<a href="./pdf/NeurIPS-2022-Jiang.pdf" target="_blank">PDF</a>, <a href="./pdf/NeurIPS-2022-Jiang-S.pdf" target="_blank">Supplementary</a>] <br>   
				<b>W. Jiang</b>, G. Li, Y. Wang, L. Zhang, and T. Yang<br>
				In Advances in Neural Information Processing Systems 35 (<b>NeurIPS 2022</b>), pages 32499 - 32511, 2022. <br><br>
				<li> Smoothed Online Convex Optimization Based on Discounted-Normal-Predictor  [<a href="./pdf/NeurIPS-2022-Zhang.pdf" target="_blank">PDF</a>, <a href="./pdf/NeurIPS-2022-Zhang-S.pdf" target="_blank">Supplementary</a>]<br>   
				L. Zhang, <b>W. Jiang</b>, J. Yi, and T. Yang<br>
				In Advances in Neural Information Processing Systems 35 (<b>NeurIPS 2022</b>), pages 4928 - 4942, 2022. <br><br>
				<li> Optimal Algorithms for Stochastic Multi-Level Compositional Optimization  [<a href="./pdf/ICML-2022-Jiang.pdf" target="_blank">PDF</a>, <a href="./bib/ICML-2022-Jiang.html" target="_blank">Bibtex</a>]<br>   
				<b>W. Jiang</b>, B. Wang, Y. Wang, L. Zhang, and T. Yang<br>	
				In Proceedings of the 39th International Conference on Machine Learning (<b>ICML 2022</b>), pages 10195 - 10216, 2022.<br><br>
                <li> Revisiting Smoothed Online Learning  [<a href="./pdf/NeurIPS-2021-Zhang-A.pdf" target="_blank">PDF</a>, <a href="./pdf/NeurIPS-2021-Zhang-A-S.pdf" target="_blank">Supplementary</a>, <a href="./bib/NeurIPS-2021-Zhang-A.html" target="_blank">Bibtex</a>]<br>
	L. Zhang, <b>W. Jiang</b>, S. Lu, and T. Yang<br>
	In Advances in Neural Information Processing Systems 34 (<b>NeurIPS 2021</b>), pages 13599 - 13612, 2021. <br><br>
                <li> Dual Adaptivity: A Universal Algorithm for Minimizing the Adaptive Regret of Convex Functions [<a href="./pdf/NeurIPS-2021-Zhang-B.pdf" target="_blank">PDF</a>, <a href="./pdf/NeurIPS-2021-Zhang-B-S.pdf" target="_blank">Supplementary</a>, <a href="./bib/NeurIPS-2021-Zhang-B.html" target="_blank">Bibtex</a>]<br>  
				L. Zhang, G. Wang, W.-W. Tu,  <b>W. Jiang</b>, and Z.-H. Zhou<br>
				In Advances in Neural Information Processing Systems 34 (<b>NeurIPS 2021</b>), pages 24968 - 24980, 2021. <br><br>
            </ol>

		<h2>Honors and Awards</h2>
            <ul>
            	<li>National Scholarship, 2023 </li>
            	<li>LAMDA Excellent Student Award, 2023</li>
            	<li>Excellent Student of Nanjing University, 2023</li>
            	<li>Tencent Scholarship, 2022</li>
            	<li>Excellent Student of Nanjing University, 2022</li>
            	<li>Industrial Bank Scholarship, 2021</li>
                <li>Excellent Student of Nanjing University, 2021</li>
                <li>Grand Champion of DeeCamp Artificial Intelligence Camp, 2020 (￥100,000)</li>
                <li>Excellent Graduate of Xi'an jiaotong University, 2020</li>
            </ul>
		<h2>Academic Service</h2>
            <ul>
            	<li>Reviewer for Conferences:  ICML 2024,2023,2022; NeurIPS 2024,2023,2022; ICLR 2024; AISTATS 2023.</li>
                <li>Reviewer for Journal: TMLR; Neurocomputing.</li>
                
            </ul>

			<h2>Teaching Assistant</h2>
            <ul>
            	<li><a href="http://www.lamda.nju.edu.cn/zhuangzh/cm2023.html" target="_blank">Computational Methods</a> (With Prof. <a href="http://ai.nju.edu.cn/zlj/" target="_blank">Lijun Zhang</a>; For Undergraduate Student, Spring, 2023)</li>
            	<li><a href="http://www.lamda.nju.edu.cn/qiuzh/optfall2021gra.html" target="_blank">Optimization Methods</a> (With Prof. <a href="http://ai.nju.edu.cn/zlj/" target="_blank">Lijun Zhang</a>; For Graduate Student, Fall, 2021)</li>
                <li><a href="http://www.lamda.nju.edu.cn/chengq/course/opt2020/opt2020.html" target="_blank">Optimization Methods</a> (With Prof. <a href="http://ai.nju.edu.cn/zlj/" target="_blank">Lijun Zhang</a>; For Undergraduate Student, Fall, 2020)</li>
                
            </ul>


		<h2>Correspondence</h2>
		<ul>
			<li>
				<p>Email: <a href="mailto:jiangw@lamda.nju.edu.cn">
						jiangw@lamda.nju.edu.cn
					</a></p>
			</li>
			<li>
				<p>Office:
					Room 327, Computer Science Building, Xianlin Campus of Nanjing University<br>
					</p>
			</li>
		</ul>

		



		<div id="footer">
			<div id="footer-text">
				Last Modified: 2024.06.06
			</div>
		</div>
	</div>


	<style>
		@font-face {
			font-family: "yourDictFontAwesome";
			src: url("chrome-extension://dmckmhkomggmpalekfadjibdcknieljf/lib/fontawesome-webfont.ttf") format("truetype");
			font-weight: normal;
			font-style: normal;
		}
	</style>
</body>

</html>